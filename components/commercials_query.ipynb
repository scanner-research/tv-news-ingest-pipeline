{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from rekall.predicates import *\n",
    "from rekall.stdlib import ingest\n",
    "from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, FlatFormat\n",
    "from vgrid import SpatialType_Bbox, SpatialType_Caption, Metadata_Generic\n",
    "from vgrid_jupyter import VGridWidget\n",
    "import urllib3, requests, os\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = [559, 1791, 3730, 3754, 10323, 11579, 17386, 20689, 24847, 24992, \n",
    "           26175, 33800, 40203, 40267, 43637, 50561, 54377, 57990, 59028, \n",
    "           63965, 67300]\n",
    "test_set = [385, 8697, 9215, 9901, 12837, 13993, 14925, 18700, 23541, # 31902,\n",
    "            32996, 36755, 50164, 52945, 55711, 57748, 59789, 60433, 136732,\n",
    "            149097, 169420]\n",
    "# test_set = [385, 8697, 9215, 9901, 12837, 13993, 14925, 18700, 23541,\n",
    "#             32996, 36755, 50164, 52945, 55711, 57748, 59789, 60433, 136732,\n",
    "#             149097, 169420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2288/2288 [00:00<00:00, 147299.58it/s]\n"
     ]
    }
   ],
   "source": [
    "VIDEO_COLLECTION_BASEURL = \"http://olimar.stanford.edu/hdd/tvnews-commercials\"\n",
    "VIDEO_METADATA_FILENAME = \"video_meta_commercials.json\"\n",
    "\n",
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, VIDEO_METADATA_FILENAME), verify=False)\n",
    "video_collection = req.json()\n",
    "\n",
    "video_metadata = [\n",
    "    VideoMetadata(v[\"path\"], v[\"id\"], v[\"fps\"], int(v[\"num_frames\"]), v[\"width\"], v[\"height\"])\n",
    "    for v in video_collection\n",
    "]\n",
    "\n",
    "def load_json(video_baseurl, json_path):\n",
    "    req = requests.get(os.path.join(video_baseurl, json_path), verify=False)\n",
    "    json_objs = req.json()\n",
    "    ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "        json_objs,\n",
    "        ingest.getter_accessor,\n",
    "        {\n",
    "            'key': 'video_id',\n",
    "            't1': 'start',\n",
    "            't2': 'end'\n",
    "        },\n",
    "        with_payload = lambda item: item,\n",
    "        progress = True\n",
    "    )\n",
    "    return ism\n",
    "\n",
    "COMMERCIALS_JSON = 'all_commercials.json'\n",
    "commercials = load_json(VIDEO_COLLECTION_BASEURL, COMMERCIALS_JSON)\n",
    "\n",
    "# CAPTIONS_JSON = \"captions_commercials.json\"\n",
    "\n",
    "# def load_json_captions(video_baseurl, json_path):\n",
    "#     req = requests.get(os.path.join(video_baseurl, json_path), verify=False)\n",
    "#     json_objs = req.json()\n",
    "#     ism = ingest.ism_from_iterable_with_schema_bounds3D(\n",
    "#         json_objs,\n",
    "#         ingest.getter_accessor,\n",
    "#         {\n",
    "#             'key': 'video_id',\n",
    "#             't1': 'start',\n",
    "#             't2': 'end'\n",
    "#         },\n",
    "#         with_payload = lambda item: item,\n",
    "#         progress = True\n",
    "#     )\n",
    "#     return ism\n",
    "\n",
    "# captions = load_json_captions(VIDEO_COLLECTION_BASEURL, CAPTIONS_JSON).map(\n",
    "#     lambda caption: Interval(caption['bounds'], caption['payload']['caption'])\n",
    "# )\n",
    "\n",
    "CAPTIONS_PICKLE = \"captions_commercials_aligned.pkl\"\n",
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, CAPTIONS_PICKLE), verify=False)\n",
    "captions_by_id = pickle.loads(req.content)\n",
    "\n",
    "captions = IntervalSetMapping({\n",
    "    video_id: IntervalSet([\n",
    "        Interval(Bounds3D(start, end), payload=text)\n",
    "        for text, start, end in captions_by_id[video_id]\n",
    "    ])\n",
    "    for video_id in dev_set + test_set if video_id in captions_by_id\n",
    "})\n",
    "\n",
    "BLACK_FRAMES_PATH = 'black_frame_all.pkl'\n",
    "req = requests.get(os.path.join(VIDEO_COLLECTION_BASEURL, BLACK_FRAMES_PATH), verify=False)\n",
    "\n",
    "black_frames_by_id = pickle.loads(req.content)\n",
    "\n",
    "black_frames = IntervalSetMapping({\n",
    "    video_id: IntervalSet([\n",
    "        Interval(Bounds3D(frame_num, frame_num + 1))\n",
    "        for frame_num in black_frames_by_id[video_id]\n",
    "    ])\n",
    "    for video_id in dev_set + test_set\n",
    "})\n",
    "\n",
    "whole_video = IntervalSetMapping({\n",
    "    vm.id: IntervalSet([Interval(Bounds3D(0, vm.num_frames / vm.fps))])\n",
    "    for vm in video_metadata\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval and Second-Frame Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{33800: 109, 60433: 106, 136732: 114, 12837: 132, 559: 6, 26175: 46, 14925: 82, 10323: 100, 54377: 103, 149097: 117, 43637: 105, 57990: 105, 3730: 475, 59028: 119, 31902: 107, 13993: 131, 3754: 93, 9901: 106, 20689: 118, 52945: 106, 67300: 115, 32996: 129, 1791: 119, 40203: 360, 18700: 120, 24847: 119, 11579: 119, 40267: 104, 50561: 128, 385: 102, 59789: 127, 36755: 121, 57748: 110, 55711: 104, 24992: 107, 169420: 80, 63965: 94, 17386: 114, 50164: 111, 23541: 115, 8697: 124, 9215: 127}\n",
      "{50561: 366, 385: 366, 57990: 366, 33800: 366, 40203: 1086, 18700: 366, 59789: 366, 24847: 367, 60433: 366, 3730: 1446, 36755: 366, 59028: 366, 57748: 366, 136732: 366, 31902: 366, 55711: 366, 24992: 367, 12837: 366, 13993: 367, 3754: 367, 9901: 366, 559: 366, 1791: 366, 11579: 366, 26175: 366, 40267: 366, 169420: 360, 14925: 186, 20689: 367, 52945: 366, 10323: 367, 63965: 360, 67300: 360, 32996: 367, 54377: 366, 17386: 366, 149097: 360, 50164: 366, 43637: 366, 23541: 366, 8697: 366, 9215: 366}\n"
     ]
    }
   ],
   "source": [
    "vm_by_video = {\n",
    "    video_id: [vm for vm in video_metadata if vm.id == video_id][0]\n",
    "    for video_id in dev_set + test_set\n",
    "}\n",
    "\n",
    "def frame_second_conversion(c, mode='f2s'):\n",
    "    def second_to_frame(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = int(curr_bounds['t1']*float(fps))\n",
    "            curr_bounds['t2'] = int(curr_bounds['t2']*float(fps))\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    def frame_to_second(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            curr_bounds = intrvl['bounds'].copy()\n",
    "            curr_bounds['t1'] = curr_bounds['t1']/float(fps)\n",
    "            curr_bounds['t2'] = curr_bounds['t2']/float(fps)\n",
    "            i2['bounds'] = curr_bounds\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    if mode=='f2s':\n",
    "        fn = frame_to_second\n",
    "    if mode=='s2f':\n",
    "        fn = second_to_frame\n",
    "    output = {}\n",
    "    for vid, intervals in c.get_grouped_intervals().items():\n",
    "        output[vid] = intervals.map(fn(vm_by_video[vid].fps))\n",
    "    return IntervalSetMapping(output)\n",
    "\n",
    "def frame_to_second_collection(c, cast_to_int = True):\n",
    "    seconds = frame_second_conversion(c, 'f2s')\n",
    "    if cast_to_int:\n",
    "        return seconds.map(lambda intrvl: Interval(\n",
    "            Bounds3D(int(intrvl['t1']), int(intrvl['t2']))\n",
    "        ))\n",
    "    \n",
    "    return frame_second_conversion(c, 'f2s')\n",
    "\n",
    "def second_to_frame_collection(c):\n",
    "    return frame_second_conversion(c, 's2f')\n",
    "\n",
    "interval = 10\n",
    "segs_dict = {}\n",
    "for video_id in dev_set + test_set:\n",
    "    video = vm_by_video[video_id]\n",
    "    iset = IntervalSet([\n",
    "        Interval(Bounds3D(i - interval / 2, i + interval / 2))\n",
    "        for i in range(0, int(video.num_frames / video.fps), interval)\n",
    "    ])\n",
    "    segs_dict[video_id] = iset\n",
    "    \n",
    "segments = IntervalSetMapping(segs_dict)\n",
    "segments_all_negative = segments.map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 0)\n",
    ")\n",
    "\n",
    "def filter_by_id(ism, valid_ids):\n",
    "    return IntervalSetMapping({\n",
    "        vid: ism.get_grouped_intervals()[vid]\n",
    "        for vid in list(ism.get_grouped_intervals().keys()) if vid in valid_ids\n",
    "    })\n",
    "\n",
    "commercial_segments = segments.filter_against(\n",
    "    commercials, predicate = overlaps()\n",
    ").map(\n",
    "    lambda intrvl: Interval(intrvl['bounds'], 1)\n",
    ")\n",
    "\n",
    "commercial_labels = segments_all_negative.minus(\n",
    "    commercial_segments\n",
    ").union(commercial_segments)\n",
    "\n",
    "print(commercial_segments.size())\n",
    "print(commercial_labels.size())\n",
    "\n",
    "def evaluate_preds(predictions, commercial_labels, video_ids):\n",
    "    predictions = filter_by_id(predictions, video_ids)\n",
    "    commercial_labels = filter_by_id(commercial_labels, video_ids)\n",
    "    \n",
    "    prediction_segments = segments.filter_against(\n",
    "        predictions,\n",
    "        predicate = overlaps()\n",
    "    ).map(lambda intrvl: Interval(intrvl['bounds'], 1))\n",
    "\n",
    "    prediction_labels = segments_all_negative.minus(\n",
    "        prediction_segments\n",
    "    ).union(prediction_segments)\n",
    "\n",
    "    prediction_scores = prediction_labels.join(\n",
    "        commercial_labels,\n",
    "        predicate = equal(),\n",
    "        merge_op = lambda i1, i2: Interval(\n",
    "            i1['bounds'],\n",
    "            'tp' if i1['payload'] == i2['payload'] and i1['payload'] == 1 else\n",
    "            'tn' if i1['payload'] == i2['payload'] and i1['payload'] == 0 else\n",
    "            'fp' if i1['payload'] != i2['payload'] and i1['payload'] == 1 else\n",
    "            'fn'\n",
    "        ),\n",
    "        window = 0\n",
    "    )\n",
    "    \n",
    "    def precision_recall_f1(pred_labels):\n",
    "        def sum_values(obj):\n",
    "            return sum([v for v in list(obj.values())])\n",
    "        tp = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'tp')).size())\n",
    "        tn = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'tn')).size())\n",
    "        fp = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'fp')).size())\n",
    "        fn = sum_values(pred_labels.filter(payload_satisfies(lambda p: p == 'fn')).size())\n",
    "\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0.\n",
    "        recall = tp / (tp + fn)  if tp + fn > 0 else 0.\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0. else 0.\n",
    "\n",
    "        return (precision, recall, f1, tp, tn, fp, fn)\n",
    "    \n",
    "    return precision_recall_f1(prediction_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercials Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commercials_query(captions, black_frames, whole_video, params={}):\n",
    "    magic_numbers = {\n",
    "        'RELIABLE_TEXT_DURATION': 5,\n",
    "        'BLACKFRAME_COALESCE_EPSILON': 2,\n",
    "        'CAPTIONS_COALESCE_EPSILON': 2,\n",
    "        'COMMERCIAL_FOLD_EPSILON': 5,\n",
    "        'MIN_COMMERCIAL_TIME': 10,\n",
    "        'MAX_COMMERCIAL_TIME': 300,\n",
    "        'LOWERCASE_COALESCE_EPSILON': 2,\n",
    "        'MIN_LOWERTEXT': 0.5,\n",
    "        'MIN_LOWERWINDOW': 15,\n",
    "        'MAX_LOWERWINDOW_GAP': 60,\n",
    "        'MIN_BLANKWINDOW': 30,\n",
    "        'MAX_BLANKWINDOW': 270,\n",
    "        'MAX_MERGE_GAP': 120,\n",
    "        'MAX_MERGE_DURATION': 300,\n",
    "    }\n",
    "    \n",
    "    RELIABLE_TEXT_DURATION = magic_numbers['RELIABLE_TEXT_DURATION']\n",
    "    BLACKFRAME_COALESCE_EPSILON = magic_numbers['BLACKFRAME_COALESCE_EPSILON']\n",
    "    CAPTIONS_COALESCE_EPSILON = magic_numbers['CAPTIONS_COALESCE_EPSILON']\n",
    "    COMMERCIAL_FOLD_EPSILON = magic_numbers['COMMERCIAL_FOLD_EPSILON']\n",
    "    MIN_COMMERCIAL_TIME = magic_numbers['MIN_COMMERCIAL_TIME']\n",
    "    MAX_COMMERCIAL_TIME = magic_numbers['MAX_COMMERCIAL_TIME']\n",
    "    LOWERCASE_COALESCE_EPSILON = magic_numbers['LOWERCASE_COALESCE_EPSILON']\n",
    "    MIN_LOWERTEXT = magic_numbers['MIN_LOWERTEXT']\n",
    "    MIN_LOWERWINDOW = magic_numbers['MIN_LOWERWINDOW']\n",
    "    MAX_LOWERWINDOW_GAP = magic_numbers['MAX_LOWERWINDOW_GAP']\n",
    "    MIN_BLANKWINDOW = magic_numbers['MIN_BLANKWINDOW']\n",
    "    MAX_BLANKWINDOW = magic_numbers['MAX_BLANKWINDOW']\n",
    "    MAX_MERGE_GAP = magic_numbers['MAX_MERGE_GAP']\n",
    "    MAX_MERGE_DURATION = magic_numbers['MAX_MERGE_DURATION']\n",
    "    \n",
    "    black_windows = frame_to_second_collection(black_frames.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = BLACKFRAME_COALESCE_EPSILON\n",
    "    ), cast_to_int = False)\n",
    "    \n",
    "    arrow_intervals = captions.filter(\n",
    "        lambda intrvl: '>>' in intrvl['payload'] and '{' not in intrvl['payload']\n",
    "    )\n",
    "    arrow_announcer_intervals = captions.filter(\n",
    "        lambda intrvl: '>> Announcer:' in intrvl['payload'] and '{' not in intrvl['payload']\n",
    "    )\n",
    "    arrow_having_intervals = captions.filter(\n",
    "        lambda intrvl: '>> HAVING' in intrvl['payload'] and '{' not in intrvl['payload']\n",
    "    )\n",
    "    \n",
    "    transcript_intervals = captions.filter(\n",
    "        lambda intrvl: '{' not in intrvl['payload']\n",
    "    ).coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = CAPTIONS_COALESCE_EPSILON\n",
    "    )\n",
    "    \n",
    "    reliable_transcripts = transcript_intervals.filter_size(min_size = RELIABLE_TEXT_DURATION)\n",
    "    arrow_intervals = arrow_intervals.minus(\n",
    "        arrow_announcer_intervals\n",
    "    ).minus(\n",
    "        arrow_having_intervals\n",
    "    ).filter_against(\n",
    "        reliable_transcripts,\n",
    "        predicate = overlaps()\n",
    "    )\n",
    "    \n",
    "    all_blocks = whole_video.minus(black_windows)\n",
    "    non_commercial_blocks = all_blocks.filter_against(\n",
    "        arrow_intervals,\n",
    "        predicate = overlaps()\n",
    "    )\n",
    "    \n",
    "    commercial_blocks = whole_video.minus(non_commercial_blocks.union(black_windows))\n",
    "    \n",
    "    def fold_fn(stack, interval):\n",
    "        if interval['t2'] - interval['t1'] > MAX_COMMERCIAL_TIME:\n",
    "            interval = Interval(\n",
    "                Bounds3D(interval['t1'], interval['t1'] + MAX_COMMERCIAL_TIME))\n",
    "        if len(stack) == 0:\n",
    "            stack.append(interval)\n",
    "        else:\n",
    "            last = stack.pop()\n",
    "            if or_pred(overlaps(), after(max_dist=COMMERCIAL_FOLD_EPSILON))(interval, last):\n",
    "                if last['bounds'].span(interval['bounds']).size() > MAX_COMMERCIAL_TIME:\n",
    "                    stack.append(Interval(\n",
    "                        Bounds3D(\n",
    "                            last['t1'], \n",
    "                            last['t1'] + MAX_COMMERCIAL_TIME)))\n",
    "                else:\n",
    "                    stack.append(Interval(\n",
    "                        last['bounds'].span(interval['bounds'])\n",
    "                    ))\n",
    "            else:\n",
    "                stack.append(last)\n",
    "                stack.append(interval)\n",
    "        return stack\n",
    "    \n",
    "    commercials = commercial_blocks.fold_to_set(\n",
    "        fold_fn, init=[]\n",
    "    ).filter_size(min_size = MIN_COMMERCIAL_TIME)\n",
    "    commercials_orig = commercials\n",
    "    \n",
    "    def is_lower_text(text):\n",
    "        lower = [c for c in text if c.islower()]\n",
    "        alpha = [c for c in text if c.isalpha()]\n",
    "        if len(alpha) == 0:\n",
    "            return False\n",
    "        if 1. * len(lower) / len(alpha) > MIN_LOWERTEXT:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    lowercase_intervals = captions.filter(\n",
    "        lambda intrvl: is_lower_text(intrvl['payload'])\n",
    "    ).coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        payload_merge_op = lambda p1, p2: p1 + ' ' + p2,\n",
    "        epsilon = LOWERCASE_COALESCE_EPSILON\n",
    "    ).filter_size(min_size = MIN_LOWERWINDOW)\n",
    "    \n",
    "    commercials = commercials.union(lowercase_intervals)\n",
    "    \n",
    "    blank_intervals = whole_video.minus(\n",
    "        transcript_intervals\n",
    "    ).filter_size(\n",
    "        min_size=MIN_BLANKWINDOW, max_size=MAX_BLANKWINDOW\n",
    "    ).minus(\n",
    "        whole_video.map(\n",
    "            lambda intrvl: Interval(Bounds3D(intrvl['t2'] - 60, intrvl['t2']))\n",
    "        )\n",
    "    ).filter_size(min_size=MIN_BLANKWINDOW)\n",
    "    \n",
    "    commercials = commercials.union(blank_intervals)\n",
    "    \n",
    "    commercials = commercials.coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span,\n",
    "        epsilon = MAX_MERGE_GAP\n",
    "    ).filter_size(\n",
    "        max_size = MAX_COMMERCIAL_TIME\n",
    "    ).union(\n",
    "        commercials_orig\n",
    "    ).union(\n",
    "        lowercase_intervals\n",
    "    ).union(\n",
    "        blank_intervals\n",
    "    ).coalesce(\n",
    "        ('t1', 't2'),\n",
    "        Bounds3D.span\n",
    "    )\n",
    "    \n",
    "    return commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dev = filter_by_id(captions, dev_set)\n",
    "black_frames_dev = filter_by_id(black_frames, dev_set)\n",
    "whole_video_dev = filter_by_id(whole_video, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercials_dev = commercials_query(captions_dev, black_frames_dev, whole_video_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.942225392296719,\n",
       " 0.9579405366207396,\n",
       " 0.9500179791441927,\n",
       " 2642,\n",
       " 6559,\n",
       " 162,\n",
       " 116)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(commercials_dev, commercial_labels, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_test = filter_by_id(captions, test_set)\n",
    "black_frames_test = filter_by_id(black_frames, test_set)\n",
    "whole_video_test = filter_by_id(whole_video, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "commercials_test = commercials_query(captions_test, black_frames_test, whole_video_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9263285024154589,\n",
       " 0.9704765921552088,\n",
       " 0.9478887744593202,\n",
       " 2301,\n",
       " 4942,\n",
       " 183,\n",
       " 70)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_preds(commercials_test, commercial_labels, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rekall]",
   "language": "python",
   "name": "conda-env-rekall-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
